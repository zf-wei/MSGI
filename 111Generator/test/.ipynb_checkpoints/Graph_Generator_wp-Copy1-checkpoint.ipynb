{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cedbd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import json\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "num_cpus = cpu_count()\n",
    "\n",
    "def nodes_sample(random_disturb: bool, graph, number_of_nodes: int, percent, betweenness):\n",
    "    graph_copy = graph.copy()\n",
    "    sample_size = int(number_of_nodes * percent)\n",
    "    if random_disturb:\n",
    "        removed_nodes = random.sample(range(number_of_nodes), sample_size)\n",
    "    else:\n",
    "        removed_nodes = random.choices(range(number_of_nodes), betweenness, k=sample_size)\n",
    "    graph_copy.remove_nodes_from(removed_nodes)\n",
    "    if nx.is_connected(graph_copy):\n",
    "        return removed_nodes\n",
    "\n",
    "def call_nodes_sample(args):\n",
    "    random_disturb, graph, number_of_nodes, percent, betweenness = args\n",
    "    return nodes_sample(random_disturb=random_disturb, graph=graph, number_of_nodes=number_of_nodes, percent=percent, betweenness=betweenness)\n",
    "\n",
    "def generate_remove_procedure_wp(random_disturb: bool, mu, graph, number_of_nodes, betweenness, sample_count=50):\n",
    "    remove_procedure = []\n",
    "    pool = Pool()\n",
    "\n",
    "    for percent in np.arange(0.05, 0.86, 0.05):\n",
    "        ls = []\n",
    "        successful_samples = 0\n",
    "        print(\"000\")\n",
    "        while successful_samples < sample_count:\n",
    "            args_list = [(random_disturb, graph, number_of_nodes, percent, betweenness)] * num_cpus\n",
    "            results = pool.map(call_nodes_sample, args_list)\n",
    "\n",
    "            for temp in results:\n",
    "                if temp is not None:\n",
    "                    ls.append(temp)\n",
    "                    successful_samples += 1\n",
    "            print(successful_samples)\n",
    "\n",
    "        remove_procedure.append(ls[:sample_count])\n",
    "        print(f\"{percent}，我是分割线\")\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    if random_disturb:\n",
    "        filename = f\"graph_{graph.number_of_nodes()}_{mu}.stoch_rmv\"\n",
    "    else:\n",
    "        filename = f\"graph_{graph.number_of_nodes()}_{mu}.btwn_rmv\"\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(remove_procedure, file)\n",
    "\n",
    "def remove_procedure_index(remove_procedure, num_nodes):\n",
    "    index = []\n",
    "    for sublist_list in remove_procedure:\n",
    "        sublist_index = []\n",
    "        for sublist in sublist_list:\n",
    "            temp = np.full(num_nodes, True)\n",
    "            temp[sublist] = False\n",
    "            sublist_index.append(temp)\n",
    "        index.append(sublist_index)\n",
    "    return index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aebce02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#小改动\n",
    "import random\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import json\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "num_cpus = cpu_count()\n",
    "\n",
    "def nodes_sample(random_disturb: bool, graph, number_of_nodes: int, percent, betweenness):\n",
    "    graph_copy = graph.copy()\n",
    "    sample_size = int(number_of_nodes * percent)\n",
    "    if random_disturb:\n",
    "        removed_nodes = random.sample(range(number_of_nodes), sample_size)\n",
    "    else:\n",
    "        removed_nodes = random.choices(range(number_of_nodes), betweenness, k=sample_size)\n",
    "    graph_copy.remove_nodes_from(removed_nodes)\n",
    "    if nx.is_connected(graph_copy):\n",
    "        return removed_nodes\n",
    "\n",
    "def call_nodes_sample(args):\n",
    "    random_disturb, graph, number_of_nodes, percent, betweenness = args\n",
    "    return nodes_sample(random_disturb=random_disturb, graph=graph, number_of_nodes=number_of_nodes, percent=percent, betweenness=betweenness)\n",
    "\n",
    "def generate_remove_procedure_wp(random_disturb: bool, mu, graph, number_of_nodes, betweenness, sample_count=50):\n",
    "    remove_procedure = []\n",
    "    pool = Pool()\n",
    "\n",
    "    for percent in np.arange(0.05, 0.86, 0.05):\n",
    "        ls = []\n",
    "        successful_samples = 0\n",
    "        while successful_samples < sample_count:\n",
    "            results = []\n",
    "            for _ in range(num_cpus):\n",
    "                args = (random_disturb, graph, number_of_nodes, percent, betweenness)\n",
    "                result = pool.apply_async(call_nodes_sample, args=(args,))\n",
    "                results.append(result)\n",
    "\n",
    "            for temp in results:\n",
    "                if temp is not None:\n",
    "                    ls.append(temp)\n",
    "                    successful_samples += 1\n",
    "            print(successful_samples)\n",
    "\n",
    "        remove_procedure.append(ls[:sample_count])\n",
    "        print(f\"{percent}，我是分割线\")\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    if random_disturb:\n",
    "        filename = f\"graph_{graph.number_of_nodes()}_{mu}.stoch_rmv\"\n",
    "    else:\n",
    "        filename = f\"graph_{graph.number_of_nodes()}_{mu}.btwn_rmv\"\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(remove_procedure, file)\n",
    "\n",
    "def remove_procedure_index(remove_procedure, num_nodes):\n",
    "    index = []\n",
    "    for sublist_list in remove_procedure:\n",
    "        sublist_index = []\n",
    "        for sublist in sublist_list:\n",
    "            temp = np.full(num_nodes, True)\n",
    "            temp[sublist] = False\n",
    "            sublist_index.append(temp)\n",
    "        index.append(sublist_index)\n",
    "    return index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "340eaae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###新的\n",
    "import random\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import json\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "num_cpus = cpu_count()\n",
    "\n",
    "def nodes_sample(random_disturb: bool, graph, number_of_nodes: int, percent, betweenness):\n",
    "    graph_copy = graph.copy()\n",
    "    sample_size = int(number_of_nodes * percent)\n",
    "    if random_disturb:\n",
    "        removed_nodes = random.sample(range(number_of_nodes), sample_size)\n",
    "    else:\n",
    "        removed_nodes = random.choices(range(number_of_nodes), betweenness, k=sample_size)\n",
    "    graph_copy.remove_nodes_from(removed_nodes)\n",
    "    if nx.is_connected(graph_copy):\n",
    "        return removed_nodes\n",
    "\n",
    "def call_nodes_sample(args):\n",
    "    random_disturb, graph, number_of_nodes, percent, betweenness = args\n",
    "    return nodes_sample(random_disturb=random_disturb, graph=graph, number_of_nodes=number_of_nodes, percent=percent, betweenness=betweenness)\n",
    "\n",
    "def generate_remove_procedure_wp(random_disturb: bool, mu, graph, number_of_nodes, betweenness, sample_count=50):\n",
    "    remove_procedure = []\n",
    "    pool = Pool()\n",
    "\n",
    "    for percent in np.arange(0.05, 0.86, 0.05):\n",
    "        ls = []\n",
    "        successful_samples = 0\n",
    "\n",
    "        results = []\n",
    "        for _ in range(num_cpus):\n",
    "            args = (random_disturb, graph, number_of_nodes, percent, betweenness)\n",
    "            result = pool.apply_async(call_nodes_sample, args=(args,))\n",
    "            results.append(result)\n",
    "\n",
    "        for result in results:\n",
    "            temp = result.get()\n",
    "            if temp is not None:\n",
    "                ls.append(temp)\n",
    "                successful_samples += 1\n",
    "        print(successful_samples)\n",
    "        remove_procedure.append(ls[:sample_count])\n",
    "        print(f\"{percent}，我是分割线\")\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    if random_disturb:\n",
    "        filename = f\"graph_{graph.number_of_nodes()}_{mu}.stoch_rmv\"\n",
    "    else:\n",
    "        filename = f\"graph_{graph.number_of_nodes()}_{mu}.btwn_rmv\"\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(remove_procedure, file)\n",
    "\n",
    "def remove_procedure_index(remove_procedure, num_nodes):\n",
    "    index = []\n",
    "    for sublist_list in remove_procedure:\n",
    "        sublist_index = []\n",
    "        for sublist in sublist_list:\n",
    "            temp = np.full(num_nodes, True)\n",
    "            temp[sublist] = False\n",
    "            sublist_index.append(temp)\n",
    "        index.append(sublist_index)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c814209f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fuian\n",
      "000\n",
      "256\n",
      "0.05，我是分割线\n",
      "000\n",
      "256\n",
      "0.1，我是分割线\n",
      "000\n",
      "256\n",
      "0.15000000000000002，我是分割线\n",
      "000\n",
      "256\n",
      "0.2，我是分割线\n",
      "000\n",
      "256\n",
      "0.25，我是分割线\n",
      "000\n",
      "256\n",
      "0.3，我是分割线\n",
      "000\n",
      "256\n",
      "0.35000000000000003，我是分割线\n",
      "000\n",
      "256\n",
      "0.4，我是分割线\n",
      "000\n",
      "256\n",
      "0.45，我是分割线\n",
      "000\n",
      "256\n",
      "0.5，我是分割线\n",
      "000\n",
      "255\n",
      "0.55，我是分割线\n",
      "000\n",
      "247\n",
      "0.6000000000000001，我是分割线\n",
      "000\n",
      "225\n",
      "0.6500000000000001，我是分割线\n",
      "000\n",
      "162\n",
      "0.7000000000000001，我是分割线\n",
      "000\n",
      "61\n",
      "0.7500000000000001，我是分割线\n",
      "000\n",
      "6\n",
      "0.8，我是分割线\n",
      "000\n",
      "0\n",
      "0.8500000000000001，我是分割线\n",
      "------------------------------\n",
      "CPU times: user 25.3 s, sys: 6 s, total: 31.3 s\n",
      "Wall time: 34.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from networkx.generators.community import LFR_benchmark_graph\n",
    "from WGE.extract_membership import extract_intrinsic_membership\n",
    "from WGE.remove_procedure import generate_remove_procedure\n",
    "\n",
    "n = 1000\n",
    "tau1 = 2  # Power-law exponent for the degree distribution\n",
    "tau2 = 1.1  # Power-law exponent for the community size distribution\n",
    "# mu = 0.1  # Mixing parameter\n",
    "avg_deg = 25  # Average Degree\n",
    "max_deg = int(0.1 * n)  # Max Degree\n",
    "min_commu = 60  # Min Community Size\n",
    "max_commu = int(0.1 * n)  # Max Community Size\n",
    "\n",
    "MU = [0.015]\n",
    "\n",
    "for mu in MU:\n",
    "    G = LFR_benchmark_graph(\n",
    "        n, tau1, tau2, mu, average_degree=avg_deg, max_degree=max_deg, min_community=min_commu, max_community=max_commu,\n",
    "        seed=7\n",
    "    )\n",
    "\n",
    "    # Remove multi-edges and self-loops from G\n",
    "    G = nx.Graph(G)\n",
    "    selfloop_edges = list(nx.selfloop_edges(G))\n",
    "    G.remove_edges_from(selfloop_edges)\n",
    "\n",
    "\n",
    "    nx.write_edgelist(G, f\"graph_{n}_{mu}.edgelist\", delimiter=' ', data=False)\n",
    "    \n",
    "    intrinsic_membership = extract_intrinsic_membership(G)\n",
    "    membership_output_file = f\"graph_{n}_{mu}.membership\"\n",
    "    np.savetxt(membership_output_file, intrinsic_membership, delimiter=' ', fmt='%d')\n",
    "\n",
    "    # Get betweenness centrality and save it to a file\n",
    "    betweenness = list(nx.betweenness_centrality(G).values())\n",
    "    betweenness_output_file = f\"graph_{n}_{mu}.between\"\n",
    "    np.savetxt(betweenness_output_file, betweenness, delimiter=' ')\n",
    "    \n",
    "    print(\"fuian\")\n",
    "    # Genearte remove procedure\n",
    "    generate_remove_procedure_wp(random_disturb=True, mu=mu, graph=G,  \n",
    "                              number_of_nodes=G.number_of_nodes(), betweenness=betweenness, sample_count=5)\n",
    "    print(\"------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
