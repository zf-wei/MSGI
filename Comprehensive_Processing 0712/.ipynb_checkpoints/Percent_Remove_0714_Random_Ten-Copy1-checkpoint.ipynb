{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8219747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38 µs, sys: 21 µs, total: 59 µs\n",
      "Wall time: 63.7 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97363fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.95 ms, sys: 1.69 ms, total: 4.64 ms\n",
      "Wall time: 9.03 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from auxpack.utils import generate_output\n",
    "from auxpack.utils import save_scores_to_csv\n",
    "from auxpack.utils import save_to_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "238ea626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.78 s, sys: 6.94 s, total: 8.72 s\n",
      "Wall time: 590 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from auxpack.remove_procedure import generate_remove_list\n",
    "\n",
    "from auxpack.remove_procedure import remove_procedure_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd843f39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 224 ms, sys: 39.8 ms, total: 264 ms\n",
      "Wall time: 424 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#################################\n",
    "#调用 generate_output 函数\n",
    "#################################\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def Plot_Separate(output:bool, random_disturb:bool, MEAN, STD, filename):\n",
    "    # Generate x-coordinates for the data points with a step size of 0.05\n",
    "    x_values = np.arange(0.05, 0.86, 0.05)\n",
    "\n",
    "    # Create a figure with four subplots\n",
    "    fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, sharex=True)\n",
    "\n",
    "    # Plot the lines for columns 1 in the first subplot\n",
    "    ax1.plot(x_values, [MEAN[i][0] for i in range(len(MEAN))], label='Eucl & NMI', color='tab:red')\n",
    "    ax1.fill_between(x_values, np.subtract([MEAN[i][0] for i in range(len(MEAN))], [STD[i][0] for i in range(len(STD))]),\n",
    "                     np.add([MEAN[i][0] for i in range(len(MEAN))], [STD[i][0] for i in range(len(STD))]), alpha=0.2, color='tab:red')\n",
    "    ax1.set_ylabel('NMI')\n",
    "    ax1.legend()\n",
    "\n",
    "    # Plot the lines for columns 2 in the second subplot\n",
    "    ax2.plot(x_values, [MEAN[i][1] for i in range(len(MEAN))], label='Cosn & NMI', color='tab:green')\n",
    "    ax2.fill_between(x_values, np.subtract([MEAN[i][1] for i in range(len(MEAN))], [STD[i][1] for i in range(len(STD))]),\n",
    "                     np.add([MEAN[i][1] for i in range(len(MEAN))], [STD[i][1] for i in range(len(STD))]), alpha=0.2, color='tab:green')\n",
    "    ax2.set_ylabel('NMI')\n",
    "    ax2.legend()\n",
    "\n",
    "    # Plot the lines for columns 3 in the third subplot\n",
    "    ax3.plot(x_values, [MEAN[i][2] for i in range(len(MEAN))], label='Eucl & ECSim', color='tab:blue')\n",
    "    ax3.fill_between(x_values, np.subtract([MEAN[i][2] for i in range(len(MEAN))], [STD[i][2] for i in range(len(STD))]),\n",
    "                     np.add([MEAN[i][2] for i in range(len(MEAN))], [STD[i][2] for i in range(len(STD))]), alpha=0.2, color='tab:blue')\n",
    "    ax3.set_ylabel('ECSim')\n",
    "    ax3.legend()\n",
    "    \n",
    "    # Plot the lines for columns 4 in the fourth subplot\n",
    "    ax4.plot(x_values, [MEAN[i][3] for i in range(len(MEAN))], label='Cosn & ECSim', color='tab:orange')\n",
    "    ax4.fill_between(x_values, np.subtract([MEAN[i][3] for i in range(len(MEAN))], [STD[i][3] for i in range(len(STD))]),\n",
    "                     np.add([MEAN[i][3] for i in range(len(MEAN))], [STD[i][3] for i in range(len(STD))]), alpha=0.2, color='tab:orange')\n",
    "    ax4.set_xlabel('Percentage of Nodes Removed')\n",
    "    ax4.set_ylabel('ECSim')\n",
    "\n",
    "    # Remove the legend for \"Column 4\" in the fourth subplot\n",
    "    #ax4.legend(handles=ax4.lines[:-1])\n",
    "\n",
    "    # Set the x-axis scale\n",
    "    plt.xticks(np.arange(0.0, 0.9, 0.05))\n",
    "\n",
    "    # Automatically determine the lower bound for the y-axis\n",
    "    y_min = min([min(y) for y in MEAN])\n",
    "    y_max = max([max(y) for y in MEAN])\n",
    "    y_range = y_max - y_min\n",
    "    y_offset = y_range * 0.1  # Adjust the offset as needed\n",
    "    y_lower = y_min - y_offset - 0.01\n",
    "    y_upper = 1.02\n",
    "    ax1.set_ylim(y_lower, y_upper)\n",
    "    ax2.set_ylim(y_lower, y_upper)\n",
    "    ax3.set_ylim(y_lower, y_upper)\n",
    "    ax4.set_ylim(y_lower, y_upper)\n",
    "\n",
    "    # Set the y-axis tick marks\n",
    "    y_tick_step = 0.025\n",
    "    y_ticks = np.arange(np.ceil(y_lower * 10) / 10, y_upper + 0.5*y_tick_step, y_tick_step)\n",
    "    # Add horizontal reference lines\n",
    "    for y in y_ticks:\n",
    "        ax1.axhline(y=y, color='gray', linestyle='--', alpha=0.3)\n",
    "        ax2.axhline(y=y, color='gray', linestyle='--', alpha=0.3)\n",
    "        ax3.axhline(y=y, color='gray', linestyle='--', alpha=0.3)\n",
    "        ax4.axhline(y=y, color='gray', linestyle='--', alpha=0.3)\n",
    "\n",
    "    ax1.set_yticks(y_ticks)\n",
    "    ax2.set_yticks(y_ticks)\n",
    "    ax3.set_yticks(y_ticks)\n",
    "    ax4.set_yticks(y_ticks)\n",
    "\n",
    "    # Adjust the figure size\n",
    "    fig.set_size_inches(10, 20)  # Increase the height of the figure\n",
    "    fig.suptitle('Separate Plots',y=0.92)\n",
    "    \n",
    "    if output:\n",
    "        filename = filename+\"_SEPARATE\"\n",
    "\n",
    "        file_path = generate_output(random_disturb, filename+\".png\")\n",
    "        plt.savefig(file_path)    \n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cd07774",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 0 ns, total: 6 µs\n",
      "Wall time: 8.11 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#################################\n",
    "#调用 generate_output 函数\n",
    "#################################\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def Plot_Combine(output:bool, random_disturb:bool, MEAN, STD, filename):\n",
    "    # Generate x-coordinates for the data points with a step size of 0.05\n",
    "    x_values = np.arange(0.05, 0.86, 0.05)\n",
    "\n",
    "    # Create a figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n",
    "\n",
    "    # Plot the lines for columns 1 and 3 in the first subplot\n",
    "    ax1.plot(x_values, [MEAN[i][0] for i in range(len(MEAN))], label='Eucl & NMI', color='tab:red')\n",
    "    ax1.plot(x_values, [MEAN[i][2] for i in range(len(MEAN))], label='Eucl & ECSim', color='tab:blue')\n",
    "    ax1.fill_between(x_values, np.subtract([MEAN[i][0] for i in range(len(MEAN))], [STD[i][0] for i in range(len(STD))]),\n",
    "                     np.add([MEAN[i][0] for i in range(len(MEAN))], [STD[i][0] for i in range(len(STD))]), alpha=0.2, color='tab:red')\n",
    "    ax1.fill_between(x_values, np.subtract([MEAN[i][2] for i in range(len(MEAN))], [STD[i][2] for i in range(len(STD))]),\n",
    "                     np.add([MEAN[i][2] for i in range(len(MEAN))], [STD[i][2] for i in range(len(STD))]), alpha=0.2, color='tab:blue')\n",
    "    ax1.set_ylabel('NMI&ECSim')\n",
    "    ax1.legend()\n",
    "\n",
    "    # Plot the lines for columns 2 and 4 in the second subplot\n",
    "    ax2.plot(x_values, [MEAN[i][1] for i in range(len(MEAN))], label='Cosn & NMI', color='tab:green')\n",
    "    ax2.plot(x_values, [MEAN[i][3] for i in range(len(MEAN))], label='Cosn & ECSim', color='tab:orange')\n",
    "    ax2.fill_between(x_values, np.subtract([MEAN[i][1] for i in range(len(MEAN))], [STD[i][1] for i in range(len(STD))]),\n",
    "                     np.add([MEAN[i][1] for i in range(len(MEAN))], [STD[i][1] for i in range(len(STD))]), alpha=0.2, color='tab:green')\n",
    "    ax2.fill_between(x_values, np.subtract([MEAN[i][3] for i in range(len(MEAN))], [STD[i][3] for i in range(len(STD))]),\n",
    "                     np.add([MEAN[i][3] for i in range(len(MEAN))], [STD[i][3] for i in range(len(STD))]), alpha=0.2, color='tab:orange')\n",
    "    ax2.set_xlabel('Percentage of Nodes Removed')\n",
    "    ax2.set_ylabel('NMI&ECSim')\n",
    "    ax2.legend()\n",
    "    # Set the x-axis scale\n",
    "    plt.xticks(np.arange(0.0, 0.9, 0.05))\n",
    "\n",
    "    # Automatically determine the lower bound for the y-axis\n",
    "    y_min = min([min(y) for y in MEAN])\n",
    "    y_max = max([max(y) for y in MEAN])\n",
    "    y_range = y_max - y_min\n",
    "    y_offset = y_range * 0.1  # Adjust the offset as needed\n",
    "    y_lower = y_min - y_offset - 0.01\n",
    "    y_upper = 1.02\n",
    "    ax1.set_ylim(y_lower, y_upper)\n",
    "    ax2.set_ylim(y_lower, y_upper)\n",
    "\n",
    "    # Set the y-axis tick marks\n",
    "    y_tick_step = 0.025\n",
    "    y_ticks = np.arange(np.ceil(y_lower * 10) / 10, y_upper + 0.5*y_tick_step, y_tick_step)\n",
    "    # Add horizontal reference lines\n",
    "    for y in y_ticks:\n",
    "        ax1.axhline(y=y, color='gray', linestyle='--', alpha=0.3)\n",
    "        ax2.axhline(y=y, color='gray', linestyle='--', alpha=0.3)\n",
    "    \n",
    "    ax1.set_yticks(y_ticks)\n",
    "    ax2.set_yticks(y_ticks)\n",
    "\n",
    "    # Adjust the figure size\n",
    "    fig.set_size_inches(10, 12)  # Increase the height of the figure\n",
    "\n",
    "    fig.suptitle('Combined Plots', y=0.95)\n",
    "    \n",
    "    if output:\n",
    "        filename = filename+\"_COMBINE\"\n",
    "\n",
    "        file_path = generate_output(random_disturb, filename+\".png\")\n",
    "        plt.savefig(file_path)    \n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "952bdba4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 µs, sys: 0 ns, total: 11 µs\n",
      "Wall time: 16 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#################################\n",
    "#调用 generate_output 函数\n",
    "#################################\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def Plot_Total(output:bool, random_disturb:bool, MEAN, STD, filename):\n",
    "    # Generate x-coordinates for the data points with a step size of 0.05\n",
    "    x_values = np.arange(0.05, 0.86, 0.05)\n",
    "\n",
    "    # Create a figure and axes\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Plot the lines for columns 1 and 3 in the first subplot\n",
    "    ax.plot(x_values, [MEAN[i][0] for i in range(len(MEAN))], label='Eucl & NMI', color='tab:red')\n",
    "    ax.plot(x_values, [MEAN[i][2] for i in range(len(MEAN))], label='Eucl & ECSim', color='tab:blue')\n",
    "    ax.fill_between(x_values, np.subtract([MEAN[i][0] for i in range(len(MEAN))], [STD[i][0] for i in range(len(STD))]),\n",
    "                     np.add([MEAN[i][0] for i in range(len(MEAN))], [STD[i][0] for i in range(len(STD))]), alpha=0.2, color='tab:red')\n",
    "    ax.fill_between(x_values, np.subtract([MEAN[i][2] for i in range(len(MEAN))], [STD[i][2] for i in range(len(STD))]),\n",
    "                     np.add([MEAN[i][2] for i in range(len(MEAN))], [STD[i][2] for i in range(len(STD))]), alpha=0.2, color='tab:blue')\n",
    "\n",
    "    # Plot the lines for columns 2 and 4 in the second subplot\n",
    "    ax.plot(x_values, [MEAN[i][1] for i in range(len(MEAN))], label='Cosn & NMI', color='tab:green')\n",
    "    ax.plot(x_values, [MEAN[i][3] for i in range(len(MEAN))], label='Cosn & ECSim', color='tab:orange')\n",
    "    ax.fill_between(x_values, np.subtract([MEAN[i][1] for i in range(len(MEAN))], [STD[i][1] for i in range(len(STD))]),\n",
    "                     np.add([MEAN[i][1] for i in range(len(MEAN))], [STD[i][1] for i in range(len(STD))]), alpha=0.2, color='tab:green')\n",
    "    ax.fill_between(x_values, np.subtract([MEAN[i][3] for i in range(len(MEAN))], [STD[i][3] for i in range(len(STD))]),\n",
    "                     np.add([MEAN[i][3] for i in range(len(MEAN))], [STD[i][3] for i in range(len(STD))]), alpha=0.2, color='tab:orange')\n",
    "\n",
    "    # Set labels and title\n",
    "    ax.set_xlabel('Percentage of Nodes Removed')\n",
    "    ax.set_ylabel('NMI&ECSim')\n",
    "    #ax.set_title('Total Plot')\n",
    "\n",
    "    # Set the x-axis scale\n",
    "    plt.xticks(np.arange(0.0, 0.9, 0.05))\n",
    "\n",
    "    # Automatically determine the lower bound for the y-axis\n",
    "    y_min = min([min(y) for y in MEAN])\n",
    "    y_max = max([max(y) for y in MEAN])\n",
    "    y_range = y_max - y_min\n",
    "    y_offset = y_range * 0.1  # Adjust the offset as needed\n",
    "    y_lower = y_min - y_offset - 0.01\n",
    "    y_upper = 1.02\n",
    "    ax.set_ylim(y_lower, y_upper)\n",
    "\n",
    "    # Set the y-axis tick marks\n",
    "    y_tick_step = 0.025\n",
    "    y_ticks = np.arange(np.ceil(y_lower * 10) / 10, y_upper + 0.5*y_tick_step, y_tick_step)\n",
    "    # Add horizontal reference lines\n",
    "    for y in y_ticks:\n",
    "        ax.axhline(y=y, color='gray', linestyle='--', alpha=0.3)\n",
    "        \n",
    "    ax.set_yticks(y_ticks)\n",
    "\n",
    "    # Add a legend\n",
    "    ax.legend()\n",
    "\n",
    "    # Adjust the figure size\n",
    "    fig.set_size_inches(10, 6)\n",
    "    fig.suptitle('Total Plots', y=0.95)\n",
    "\n",
    "    if output:\n",
    "        filename = filename+\"_TOTAL\"\n",
    "\n",
    "        file_path = generate_output(random_disturb, filename+\".png\")\n",
    "        plt.savefig(file_path)    \n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49a5ae6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.82 s, sys: 8.42 s, total: 12.2 s\n",
      "Wall time: 9.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from gem.embedding.hope import HOPE\n",
    "from gem.embedding.lap import LaplacianEigenmaps\n",
    "from auxpack.lle import lles\n",
    "from auxpack.DeepWalk import DeepWalk\n",
    "from karateclub import MNMF\n",
    "from ge import LINE\n",
    "from node2vec import Node2Vec\n",
    "\n",
    "def perform_hope_embedding(graph, nodes_to_remove, embedding_dimension, _, __, ___):\n",
    "    graph_copy = graph.copy()\n",
    "    graph_copy.remove_nodes_from(nodes_to_remove)\n",
    "    hope_model = HOPE(d=embedding_dimension, beta=0.01)\n",
    "    embd = hope_model.learn_embedding(graph=graph_copy, is_weighted=False, no_python=True)\n",
    "    return embd\n",
    "\n",
    "def perform_laplacian_embedding(graph, nodes_to_remove, embedding_dimension, _, __, ___):\n",
    "    graph_copy = graph.copy()\n",
    "    graph_copy.remove_nodes_from(nodes_to_remove)\n",
    "    lap_model = LaplacianEigenmaps(d=embedding_dimension)\n",
    "    embd = lap_model.learn_embedding(graph=graph_copy, is_weighted=False, no_python=True)\n",
    "    return embd\n",
    "\n",
    "def perform_lle_embedding(graph, nodes_to_remove, embedding_dimension, _, __, ___):\n",
    "    graph_copy = graph.copy()\n",
    "    graph_copy.remove_nodes_from(nodes_to_remove)\n",
    "    embd = lles(graph_copy, embedding_dimension)\n",
    "    return embd\n",
    "\n",
    "def perform_deepwalk_embedding(graph, nodes_to_remove, embedding_dimension, _, __, wk=32):\n",
    "    graph_copy = graph.copy()\n",
    "    graph_copy.remove_nodes_from(nodes_to_remove)\n",
    "    model = DeepWalk(dimensions=embedding_dimension, walk_length=16, window_size=10, walk_number=10, workers=wk)\n",
    "    model.fit(graph_copy)\n",
    "    embd = model.get_embedding()\n",
    "    return embd\n",
    "\n",
    "def perform_mnmf_embedding(graph, nodes_to_remove, embedding_dimension, number_of_intrinsic_clusters, _, __):\n",
    "    graph_copy = graph.copy()\n",
    "    graph_copy.remove_nodes_from(nodes_to_remove)\n",
    "    H = nx.relabel.convert_node_labels_to_integers(graph_copy)\n",
    "    MNMF_model = MNMF(dimensions=embedding_dimension, clusters=number_of_intrinsic_clusters, \n",
    "                      lambd=0.2, alpha=0.05, beta=0.05, iterations=100, lower_control=1e-15, eta=5.0, seed=42)\n",
    "    MNMF_model.fit(H)\n",
    "    embd = MNMF_model.get_embedding()\n",
    "    return embd\n",
    "\n",
    "\n",
    "def perform_line_embedding(graph, nodes_to_remove, embedding_dimension, _, __, ___):\n",
    "    graph_copy = graph.copy()\n",
    "    graph_copy.remove_nodes_from(nodes_to_remove)\n",
    "    model = LINE(graph_copy, embedding_size=embedding_dimension, order='first')\n",
    "    model.train(batch_size=8192, epochs=50, verbose=0)\n",
    "    LINE_embd = model.get_embeddings()\n",
    "    embd = list(LINE_embd.values())\n",
    "    return embd\n",
    "\n",
    "def perform_node2vec_embedding(graph, nodes_to_remove, embedding_dimension,_, idx, wk=32):\n",
    "    graph_copy = graph.copy()\n",
    "    graph_copy.remove_nodes_from(nodes_to_remove)\n",
    "    node2vec_model = Node2Vec(graph_copy, dimensions=embedding_dimension, walk_length=16, num_walks=10, workers=wk, quiet=True)\n",
    "    node2vec_fit = node2vec_model.fit(window=10, min_count=1, batch_words=80000)\n",
    "    nodes_range = np.array(range(graph.number_of_nodes()))\n",
    "    nodes = [str(x) for x in nodes_range[idx]]\n",
    "    embd = np.array([node2vec_fit.wv[node] for node in nodes])\n",
    "    return embd\n",
    "\n",
    "def calculate_score(embd, intrinsic_membership, number_of_intrinsic_clusters):\n",
    "    intrin_list = intrinsic_membership\n",
    "    intrin_Clus = Clustering({i: [intrin_list[i]] for i in range(len(intrin_list))})\n",
    "    score = EE(number_of_intrinsic_clusters, intrin_list, intrin_Clus, embd)\n",
    "    return score\n",
    "\n",
    "def Comprehensive_Processing(output:bool, random_disturb:bool, method: int, num_cpus:int, \n",
    "                             graph, embedding_dimension, intrinsic_membership, remove_procedure, remove_procedure_index_form):\n",
    "    labels = [\"1HOPE\", \"2LAP\", \"3LLE\", \"4DeepWalk\", \"5MNMF\", \"6LINE\", \"7Node2Vec\"]\n",
    "    print(labels[method-1])\n",
    "    MEAN = []\n",
    "    STD = []\n",
    "\n",
    "    embedding_methods = {\n",
    "        1: (perform_hope_embedding, \"HOPE\"),\n",
    "        2: (perform_laplacian_embedding, \"LAP\"),\n",
    "        3: (perform_lle_embedding, \"LLE\"),\n",
    "        4: (perform_deepwalk_embedding, \"DeepWalk\"),\n",
    "        5: (perform_mnmf_embedding, \"MNMF\"),\n",
    "        6: (perform_line_embedding, \"LINE\"),\n",
    "        7: (perform_node2vec_embedding, \"Node2Vec\")\n",
    "    }\n",
    "\n",
    "    embedding_func, method_label = embedding_methods[method]\n",
    "\n",
    "    for rp, idx in zip(remove_procedure, remove_procedure_index_form):\n",
    "        scores = []\n",
    "        for nodes_to_remove, idxx in zip(rp, idx):\n",
    "            number_of_intrinsic_clusters = len(np.unique(intrinsic_membership[idxx]))\n",
    "            embd = embedding_func(graph, nodes_to_remove, embedding_dimension, number_of_intrinsic_clusters, idxx, num_cpus)\n",
    "            score = calculate_score(embd, intrinsic_membership[idxx], number_of_intrinsic_clusters)\n",
    "            scores.append(score)\n",
    "\n",
    "        array = np.array(scores)\n",
    "        mean = np.mean(array, axis=0)\n",
    "        std = np.std(array, axis=0)\n",
    "        MEAN.append(mean)\n",
    "        STD.append(std)\n",
    "        if output:\n",
    "            save_scores_to_csv(random_disturb, scores, labels[method-1] + \"_SCORES\")\n",
    "            save_to_csv(random_disturb, MEAN, labels[method-1] + \"_MEAN\")\n",
    "            save_to_csv(random_disturb, STD, labels[method-1] + \"_STD\")\n",
    "    Plot_Separate(output, random_disturb, MEAN, STD, labels[method-1])\n",
    "    Plot_Combine(output, random_disturb, MEAN, STD, labels[method-1])\n",
    "    Plot_Total(output, random_disturb, MEAN, STD, labels[method-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1dfc6c",
   "metadata": {},
   "source": [
    "The code snippet you provided references several functions that are not defined within the provided code snippet. Here are the functions that are not defined:\n",
    "\n",
    "1. `generate_output`: This function is used to generate the output file path for saving CSV files and plots. Its implementation is not included in the provided code snippet.\n",
    "\n",
    "2. `save_scores_to_csv`: This function is referenced within the `Comprehensive_Processing` function and is used to save scores to a CSV file. Its implementation is not included in the provided code snippet.\n",
    "\n",
    "3. `save_to_csv`: This function is referenced within the `Comprehensive_Processing` function and is used to save data to a CSV file. Its implementation is not included in the provided code snippet.\n",
    "\n",
    "4. `Plot_Combine`: This function is referenced within the `Comprehensive_Processing` function and is used to generate a combined plot. Its implementation is not included in the provided code snippet.\n",
    "\n",
    "5. `Plot_Total`: This function is referenced within the `Comprehensive_Processing` function and is used to generate a total plot. Its implementation is not included in the provided code snippet.\n",
    "\n",
    "6. `EE`: This function is referenced within the `calculate_score` function and is used to calculate an evaluation metric. Its implementation is not included in the provided code snippet.\n",
    "\n",
    "7. `Clustering`: This class is referenced within the `calculate_score` function and is used to create a clustering object. Its implementation is not included in the provided code snippet.\n",
    "\n",
    "Without the implementation of these missing functions, the provided code snippet will not run successfully. You will need to define or provide the implementations of these functions in order to use the code properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3845633a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%%time\\nimport os\\n\\nslurm_job_id = os.environ.get(\\'SLURM_JOB_ID\\')\\n    \\nfrom datetime import datetime\\n\\nimport networkx as nx\\nfrom networkx.generators.community import LFR_benchmark_graph\\n\\nn = 1000\\ntau1 = 2  # Power-law exponent for the degree distribution\\ntau2 = 1.1  # Power-law exponent for the community size distribution\\nmu = 0.1  # Mixing parameter\\navg_deg = 25  # Average Degree\\nmax_deg = int(0.1 * n)  # Max Degree\\nmin_commu = 60  # Min Community Size\\nmax_commu = int(0.1 * n)  # Max Community Size\\n\\nG = LFR_benchmark_graph(\\n    n, tau1, tau2, mu, average_degree=avg_deg, max_degree=max_deg, min_community=min_commu, max_community=max_commu,\\n    seed=7\\n)\\n\\n# Remove multi-edges and self-loops from G\\nG = nx.Graph(G)\\nselfloop_edges = list(nx.selfloop_edges(G))\\nG.remove_edges_from(selfloop_edges)\\n\\n# Generate a timestamp for the output file names\\nnow = datetime.now()\\n\\n# Write the graph\\'s edge list to a file\\nedge_output_file = f\"{slurm_job_id}_edgelist_{now.strftime(\\'%Y-%m-%d-%H-%M\\')}.txt\"\\nnx.write_edgelist(G, edge_output_file, delimiter=\\' \\', data=False)\\n\\nimport numpy as np\\n# Get intrinsic membership and save it to a file\\nintrinsic_communities = {frozenset(G.nodes[v][\"community\"]) for v in G}\\nintrinsic_membership = np.empty(G.number_of_nodes(), dtype=int)\\nfor node in range(G.number_of_nodes()):\\n    for index, inner_set in enumerate(intrinsic_communities):\\n        if node in inner_set:\\n            intrinsic_membership[node] = index\\n            break\\n\\nmembership_output_file = f\"{slurm_job_id}_membership_{now.strftime(\\'%Y-%m-%d-%H-%M\\')}.txt\"\\nnp.savetxt(membership_output_file, intrinsic_membership, delimiter=\\' \\', fmt=\\'%d\\')\\n\\n# Get betweenness centrality and save it to a file\\nbetweenness = list(nx.betweenness_centrality(G).values())\\nbetweenness_output_file = f\"{slurm_job_id}_betweenness_{now.strftime(\\'%Y-%m-%d-%H-%M\\')}.txt\"\\nnp.savetxt(betweenness_output_file, betweenness, delimiter=\\' \\')\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''%%time\n",
    "import os\n",
    "\n",
    "slurm_job_id = os.environ.get('SLURM_JOB_ID')\n",
    "    \n",
    "from datetime import datetime\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.generators.community import LFR_benchmark_graph\n",
    "\n",
    "n = 1000\n",
    "tau1 = 2  # Power-law exponent for the degree distribution\n",
    "tau2 = 1.1  # Power-law exponent for the community size distribution\n",
    "mu = 0.1  # Mixing parameter\n",
    "avg_deg = 25  # Average Degree\n",
    "max_deg = int(0.1 * n)  # Max Degree\n",
    "min_commu = 60  # Min Community Size\n",
    "max_commu = int(0.1 * n)  # Max Community Size\n",
    "\n",
    "G = LFR_benchmark_graph(\n",
    "    n, tau1, tau2, mu, average_degree=avg_deg, max_degree=max_deg, min_community=min_commu, max_community=max_commu,\n",
    "    seed=7\n",
    ")\n",
    "\n",
    "# Remove multi-edges and self-loops from G\n",
    "G = nx.Graph(G)\n",
    "selfloop_edges = list(nx.selfloop_edges(G))\n",
    "G.remove_edges_from(selfloop_edges)\n",
    "\n",
    "# Generate a timestamp for the output file names\n",
    "now = datetime.now()\n",
    "\n",
    "# Write the graph's edge list to a file\n",
    "edge_output_file = f\"{slurm_job_id}_edgelist_{now.strftime('%Y-%m-%d-%H-%M')}.txt\"\n",
    "nx.write_edgelist(G, edge_output_file, delimiter=' ', data=False)\n",
    "\n",
    "import numpy as np\n",
    "# Get intrinsic membership and save it to a file\n",
    "intrinsic_communities = {frozenset(G.nodes[v][\"community\"]) for v in G}\n",
    "intrinsic_membership = np.empty(G.number_of_nodes(), dtype=int)\n",
    "for node in range(G.number_of_nodes()):\n",
    "    for index, inner_set in enumerate(intrinsic_communities):\n",
    "        if node in inner_set:\n",
    "            intrinsic_membership[node] = index\n",
    "            break\n",
    "\n",
    "membership_output_file = f\"{slurm_job_id}_membership_{now.strftime('%Y-%m-%d-%H-%M')}.txt\"\n",
    "np.savetxt(membership_output_file, intrinsic_membership, delimiter=' ', fmt='%d')\n",
    "\n",
    "# Get betweenness centrality and save it to a file\n",
    "betweenness = list(nx.betweenness_centrality(G).values())\n",
    "betweenness_output_file = f\"{slurm_job_id}_betweenness_{now.strftime('%Y-%m-%d-%H-%M')}.txt\"\n",
    "np.savetxt(betweenness_output_file, betweenness, delimiter=' ')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0de505",
   "metadata": {},
   "source": [
    "以上这段代码是自洽的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "887950ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'graph_1000_0.1.edgelist'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### 读取存储的图的相关信息\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m### 从文件中读入内容并转化成 边列表\u001b[39;00m\n\u001b[1;32m      3\u001b[0m mu\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgraph_1000_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmu\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.edgelist\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      5\u001b[0m     lines \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m### Process the lines and create a list of number pairs\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'graph_1000_0.1.edgelist'"
     ]
    }
   ],
   "source": [
    "### 读取存储的图的相关信息\n",
    "### 从文件中读入内容并转化成 边列表\n",
    "mu=0.1\n",
    "with open(f'graph_1000_{mu}.edgelist', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "### Process the lines and create a list of number pairs\n",
    "edge_list = []\n",
    "for line in lines:\n",
    "    pair = tuple(map(int, line.strip().split()))\n",
    "    edge_list.append(pair)\n",
    "\n",
    "### Print the list of number pairs\n",
    "#print(edge_list)\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "### 新建一个图 \n",
    "G0 = nx.Graph()\n",
    "\n",
    "### 向图添加边\n",
    "G0.add_edges_from(edge_list)\n",
    "\n",
    "### 记录有几个结点\n",
    "N = G0.number_of_nodes()\n",
    "\n",
    "### Load Community Info\n",
    "import numpy as np\n",
    "\n",
    "membership_list = f'graph_1000_{mu}.membership'\n",
    "intrinsic_membership = np.loadtxt(membership_list, dtype=int)\n",
    "\n",
    "btwn_file = f'graph_1000_{mu}.between'\n",
    "betweenness = np.loadtxt(btwn_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5d7e71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from auxpack.eval_embd import eval_embd as EE\n",
    "from clusim.clustering import Clustering\n",
    "\n",
    "D=20\n",
    "\n",
    "output_flag=False\n",
    "random_disturb=True\n",
    "\n",
    "num_cpus_n2v = 1\n",
    "\n",
    "import multiprocessing\n",
    "num_cpus = multiprocessing.cpu_count()\n",
    "print(num_cpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d37f517",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#需要调用 generate_remove_list\n",
    "\n",
    "remove_procedure = generate_remove_list(random_disturb=random_disturb, graph=G,  number_of_nodes=G.number_of_nodes(), betweenness=betweenness)\n",
    "\n",
    "### 读取存储的删除顶点的顺序信息\n",
    "'''\n",
    "with open('Graph_Rmv_Stoch_2023-07-11-18/remove_procedure.txt', 'r') as file:\n",
    "    loaded_data = json.load(file)\n",
    "loaded_data == ls\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3c250d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#需要调用 remove_procedure_index\n",
    "index = remove_procedure_index(remove_procedure=remove_procedure, num_nodes=G.number_of_nodes())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b389dd",
   "metadata": {},
   "source": [
    "下面的各个 Cell 调用了 Comprehensive_Processing 函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a654f4b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "Comprehensive_Processing(output=output_flag, random_disturb=random_disturb, method=1, num_cpus=num_cpus, graph = G, embedding_dimension=D, \n",
    "                        intrinsic_membership=intrinsic_membership, remove_procedure=remove_procedure, remove_procedure_index_form=index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
