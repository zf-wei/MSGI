{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e34cc637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09f44d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 使用 networkx 包中的函数 LFR_benchmark_graph 生成随机图\n",
    "import networkx as nx\n",
    "from networkx.generators.community import LFR_benchmark_graph\n",
    "\n",
    "n = 1000\n",
    "tau1 = 2  # Power-law exponent for the degree distribution\n",
    "tau2 = 1.1 # Power-law exponent for the community size distribution \n",
    "            #S hould be >1\n",
    "mu = 0.05 # Mixing parameter\n",
    "avg_deg = 25 # Average Degree\n",
    "max_deg = 100 # Max Degree\n",
    "min_commu = 50 # Min Community Size\n",
    "max_commu = 100 # Max Community Size\n",
    "\n",
    "\n",
    "G = LFR_benchmark_graph(\n",
    "    n, tau1, tau2, mu, average_degree=avg_deg, max_degree=max_deg, min_community=min_commu, max_community=max_commu, \n",
    "    seed=2\n",
    ")\n",
    "\n",
    "# nx.draw(G, pos=nx.spring_layout(G),node_color='r', node_size=3, edge_color='b')  # Draw the graph generated above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6080beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 去掉 G 中的重边和自环 \n",
    "G = nx.Graph(G) # Remove multi-edges\n",
    "\n",
    "selfloop_edges = list(nx.selfloop_edges(G)) # a list of self loops\n",
    "\n",
    "G.remove_edges_from(selfloop_edges) # Remove self-loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e96f2378",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LFR 图是有内在的社群结构的，每个节点的社群存储在其 community 属性中，是一个 set\n",
    "# 通过运行循环，按照内在的社群结构给每个节点一个标签 即为其 intrinsic_membership\n",
    "# 为了方便 intrinsic_membership 一开始是作为一个 dict 存储的\n",
    "intrinsic_communities = {frozenset(G.nodes[v][\"community\"]) for v in G}\n",
    "intrinsic_membership = {}\n",
    "for node in range(G.number_of_nodes()):\n",
    "    for index, inner_set in enumerate(intrinsic_communities):\n",
    "        if node in inner_set:\n",
    "            intrinsic_membership[node] = index\n",
    "            break\n",
    "# intrinsic_membership = list(intrinsic_membership.values())\n",
    "\n",
    "# 存储 list 和 clustering 格式的拷贝 省得以后需要再做类型转换了\n",
    "intrinsic_list = list(intrinsic_membership.values())\n",
    "from clusim.clustering import Clustering\n",
    "intrinsic_clustering = Clustering(elm2clu_dict={i: [intrinsic_membership[i]] for i in intrinsic_membership.keys()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d78f685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Louvain algorithm gives 14 communities.\n"
     ]
    }
   ],
   "source": [
    "### 利用 Louvain 算法进行社群识别并画图\n",
    "# louvain_membership 是作为一个 dict 给出的\n",
    "from community import community_louvain\n",
    "\n",
    "louvain_membership = community_louvain.best_partition(G)\n",
    "\n",
    "print(f\"Louvain algorithm gives {max(louvain_membership.values())+1} communities.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "430920de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infomap algorithm gives 14 communities.\n"
     ]
    }
   ],
   "source": [
    "### 利用 InfoMap 算法进行社群识别\n",
    "# 输出类型为一个 list\n",
    "\n",
    "# Convert the NetworkX graph to an igraph graph\n",
    "import igraph as ig\n",
    "iG = ig.Graph.from_networkx(G)\n",
    "\n",
    "# Perform Infomap clustering using igraph, and get the membership as a list\n",
    "infomap_membership = iG.community_infomap().membership # 类型为 list\n",
    "\n",
    "print(f\"Infomap algorithm gives {max(infomap_membership)+1} communities.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3471ba2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 计算 NMI\n",
    "# 我自己设计的函数可以接受 list 或者 dictl 类型的输入\n",
    "# 内在的社群结构 intrinsic_membership 和\n",
    "# Louvain 算法给出的 louvain_membership \n",
    "\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "def NMI(clus1, clus2): # NMI函数可以接受的参数类型可以是 dic 或者 list\n",
    "    if isinstance(clus1, dict):\n",
    "        clus1 = list(clus1)\n",
    "    if isinstance(clus2, dict):\n",
    "        clus2 = list(clus2)     \n",
    "    return normalized_mutual_info_score(clus1, clus2)\n",
    "\n",
    "### 使用范例\n",
    "NMI(louvain_membership, intrinsic_membership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e73115c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 计算 ECSim 的函数\n",
    "\n",
    "# 这个函数将 list 或者 dict 类型的聚类结果进行类型转换\n",
    "from clusim.clustering import Clustering\n",
    "\n",
    "def to_clus(input):\n",
    "    if isinstance(input, list):\n",
    "        elm2clu_dict = {i: [input[i]] for i in range(len(input))}\n",
    "    elif isinstance(input, dict):\n",
    "        elm2clu_dict = {i: [input[i]] for i in input.keys()}\n",
    "    else:\n",
    "        raise ValueError(\"Input must be a list or a dictionary.\")\n",
    "\n",
    "    return Clustering(elm2clu_dict)\n",
    "\n",
    "\n",
    "import clusim.sim as sim\n",
    "def ECSim(clus1, clus2): #ECsim函数可以接受的参数类型可以是 dic, list, 或者 Clustering\n",
    "    if not isinstance(clus1, Clustering):\n",
    "        clus1 = to_clus(clus1)\n",
    "    if not isinstance(clus2, Clustering):\n",
    "        clus2 = to_clus(clus2)     \n",
    "    return sim.element_sim(clus1, clus2, alpha=0.9)\n",
    "\n",
    "### 使用范例\n",
    "ECSim(louvain_membership, intrinsic_membership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c230f5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 聚类算法 输出NMI及 ECSim\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "\n",
    "def evaluate_cluster(intr_list, intr_clus, evala): \n",
    "# 输入参数 intr的类型为 dict, 为内蕴聚类\n",
    "# eval 的类型为向量 表示嵌入向量\n",
    "    return_val = [] # 首先准备好返回值 \n",
    "    ## 首先做 K Mean\n",
    "    K = max(intr_list) + 1\n",
    "    # Create a Spark DataFrame from the points\n",
    "    # from pyspark.sql import SparkSession\n",
    "    # from pyspark.ml.linalg import Vectors\n",
    "\n",
    "    evala_spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "    evala_vec = [Vectors.dense(row) for row in evala]\n",
    "    \n",
    "    evala_prep = SparkSession.builder.getOrCreate().\\\n",
    "                            createDataFrame([(vector,) for vector in evala_vec], [\"embd\"])\n",
    "\n",
    "    # from pyspark.ml.clustering import KMeans\n",
    "\n",
    "    # Create and fit the KMeans model\n",
    "    euclid_kmeans = KMeans(k=K, featuresCol=\"embd\")\n",
    "    cosine_kmeans = KMeans(k=K, featuresCol=\"embd\", distanceMeasure=\"cosine\")\n",
    "    evala_euclid_model = euclid_kmeans.fit(evala_prep)\n",
    "    evala_cosine_model = cosine_kmeans.fit(evala_prep)\n",
    "\n",
    "\n",
    "    # Add the cluster assignment to the DataFrame\n",
    "    evala_euclid = evala_euclid_model.transform(evala_prep)\n",
    "    evala_cosine = evala_cosine_model.transform(evala_prep)\n",
    "\n",
    "\n",
    "    # Extract the cluster assignment and convert it to a list\n",
    "    evala_euclid_membership = evala_euclid.select(\"prediction\").rdd.flatMap(lambda x: x).collect()\n",
    "    evala_cosine_membership = evala_cosine.select(\"prediction\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "    ## 然后开始与内蕴聚类进行比较\n",
    "    return_val.append(normalized_mutual_info_score(evala_euclid_membership, intr_list))\n",
    "    return_val.append(normalized_mutual_info_score(evala_cosine_membership, intr_list))\n",
    "    \n",
    "    \n",
    "    evala_euclid_clustering = Clustering(elm2clu_dict={i: [evala_euclid_membership[i]] for i in range(len(evala_euclid_membership))})\n",
    "    evala_cosine_clustering = Clustering(elm2clu_dict={i: [evala_cosine_membership[i]] for i in range(len(evala_cosine_membership))})\n",
    "    \n",
    "    evala_euclid_similarity = sim.element_sim(intr_clus, evala_euclid_clustering, alpha=0.9)\n",
    "    evala_cosine_similarity = sim.element_sim(intr_clus, evala_cosine_clustering, alpha=0.9)\n",
    "    return_val.append(evala_euclid_similarity)\n",
    "    return_val.append(evala_cosine_similarity)\n",
    "    \n",
    "    return return_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03d9fc45",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD error (low rank): 1.446638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/06/24 14:31:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/06/24 14:31:13 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9100566850958083, 0.9191008030411808, 0.7332394108689805, 0.823510680567314]\n"
     ]
    }
   ],
   "source": [
    "### 1 HOPE 方法\n",
    "from gem.embedding.hope import HOPE\n",
    "\n",
    "hope_model = HOPE(d=20, beta=0.01) \n",
    "# A higher value of beta places more emphasis on capturing higher-order proximities\n",
    "\n",
    "hope_embd = hope_model.learn_embedding(graph=G, is_weighted=False, no_python=True)\n",
    "print(evaluate_cluster(intrinsic_list, intrinsic_clustering, hope_embd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9f48c7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laplacian matrix recon. error (low rank): 32.016612\n",
      "[0.9751187229528936, 0.9654938155479856, 0.9082993311036789, 0.8871015384615384]\n"
     ]
    }
   ],
   "source": [
    "### 2 Laplacian 方法\n",
    "from gem.embedding.lap import LaplacianEigenmaps\n",
    "lap_model = LaplacianEigenmaps(d=20)\n",
    "\n",
    "lap_embd = lap_model.learn_embedding(graph=G, is_weighted=True, no_python=True)\n",
    "print(evaluate_cluster(intrinsic_list, intrinsic_clustering, lap_embd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0345add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9689192297834323, 0.995859467181148, 0.8982627917444431, 0.9940702722363548]\n"
     ]
    }
   ],
   "source": [
    "### 3 MNMF 方法\n",
    "\n",
    "from karateclub import MNMF\n",
    "\n",
    "# Create an instance of the MNMF model\n",
    "MNMF_model = MNMF(dimensions = 64, clusters = 14, lambd = 0.2, \n",
    "             alpha = 0.05, beta = 0.05, iterations = 100, \n",
    "             lower_control = 1e-15, eta = 5.0, seed = 42)\n",
    "\n",
    "# Fit the model to the graph\n",
    "MNMF_model.fit(G)\n",
    "\n",
    "# Obtain the graph embeddings\n",
    "MNMF_embd = MNMF_model.get_embedding()\n",
    "print(evaluate_cluster(intrinsic_list, intrinsic_clustering, MNMF_embd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f43097d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a6bbce5424b4726b325ae1aed690810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 2/2 [00:00<00:00,  5.53it/s]\n",
      "Generating walks (CPU: 2): 100%|██████████| 2/2 [00:00<00:00,  5.67it/s]\n",
      "Generating walks (CPU: 3): 100%|██████████| 2/2 [00:00<00:00,  5.62it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 2/2 [00:00<00:00,  5.54it/s]\n",
      "Generating walks (CPU: 5): 100%|██████████| 2/2 [00:00<00:00,  5.60it/s]\n",
      "Generating walks (CPU: 6): 100%|██████████| 2/2 [00:00<00:00,  5.54it/s]\n",
      "Generating walks (CPU: 7): 100%|██████████| 2/2 [00:00<00:00,  5.65it/s]\n",
      "Generating walks (CPU: 8): 100%|██████████| 2/2 [00:00<00:00,  5.63it/s]\n",
      "Generating walks (CPU: 9): 100%|██████████| 2/2 [00:00<00:00,  5.49it/s]\n",
      "Generating walks (CPU: 10): 100%|██████████| 2/2 [00:00<00:00,  5.49it/s]\n",
      "Generating walks (CPU: 11): 100%|██████████| 2/2 [00:00<00:00,  5.61it/s]\n",
      "Generating walks (CPU: 12): 100%|██████████| 2/2 [00:00<00:00,  5.58it/s]\n",
      "Generating walks (CPU: 13): 100%|██████████| 2/2 [00:00<00:00,  5.47it/s]\n",
      "Generating walks (CPU: 14): 100%|██████████| 2/2 [00:00<00:00,  5.61it/s]\n",
      "Generating walks (CPU: 15): 100%|██████████| 2/2 [00:00<00:00,  5.67it/s]\n",
      "Generating walks (CPU: 16): 100%|██████████| 2/2 [00:00<00:00,  5.64it/s]\n",
      "Generating walks (CPU: 17): 100%|██████████| 2/2 [00:00<00:00,  5.59it/s]\n",
      "Generating walks (CPU: 18): 100%|██████████| 2/2 [00:00<00:00,  5.69it/s]\n",
      "Generating walks (CPU: 19): 100%|██████████| 1/1 [00:00<00:00,  5.63it/s]\n",
      "Generating walks (CPU: 20): 100%|██████████| 1/1 [00:00<00:00,  5.47it/s]\n",
      "Generating walks (CPU: 21): 100%|██████████| 1/1 [00:00<00:00,  5.65it/s]\n",
      "Generating walks (CPU: 22): 100%|██████████| 1/1 [00:00<00:00,  5.61it/s]\n",
      "Generating walks (CPU: 23): 100%|██████████| 1/1 [00:00<00:00,  5.48it/s]\n",
      "Generating walks (CPU: 24): 100%|██████████| 1/1 [00:00<00:00,  5.55it/s]\n",
      "Generating walks (CPU: 25): 100%|██████████| 1/1 [00:00<00:00,  5.61it/s]\n",
      "Generating walks (CPU: 26): 100%|██████████| 1/1 [00:00<00:00,  5.37it/s]\n",
      "Generating walks (CPU: 27): 100%|██████████| 1/1 [00:00<00:00,  5.59it/s]\n",
      "Generating walks (CPU: 28): 100%|██████████| 1/1 [00:00<00:00,  5.52it/s]\n",
      "Generating walks (CPU: 29): 100%|██████████| 1/1 [00:00<00:00,  5.62it/s]\n",
      "Generating walks (CPU: 30): 100%|██████████| 1/1 [00:00<00:00,  5.38it/s]\n",
      "Generating walks (CPU: 31): 100%|██████████| 1/1 [00:00<00:00,  5.54it/s]\n",
      "Generating walks (CPU: 32): 100%|██████████| 1/1 [00:00<00:00,  6.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding already generated!!\n",
      "[0.9718010208240403, 0.9450323949147932, 0.8981909838562291, 0.8047615023814515]\n",
      "CPU times: user 4min 7s, sys: 563 ms, total: 4min 8s\n",
      "Wall time: 33.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### 4 Node2Vec 方法 \n",
    "\n",
    "from node2vec import Node2Vec\n",
    "\n",
    "# Precompute probabilities and generate walks - **ON WINDOWS ONLY WORKS WITH workers=1**\n",
    "node2vec_model = Node2Vec(G, dimensions=64, walk_length=30, num_walks=50, workers=32) #, temp_folder='test' # Use temp_folder for big graphs\n",
    " \n",
    "# Embed nodes \n",
    "node2vev_fit = node2vec_model.fit(window=10, min_count=1, batch_words=4096)  \n",
    "# Any keywords acceptable by gensim.Word2Vec can be passed, `dimensions` and `workers` are automatically passed (from the Node2Vec constructor)\n",
    "print(\"Embedding already generated!!\")\n",
    "node2vec_embd=[]\n",
    "for i in range(G.number_of_nodes()):\n",
    "    node2vec_embd.append(node2vev_fit.wv[f'{i}'])\n",
    "\n",
    "print(evaluate_cluster(intrinsic_list, intrinsic_clustering, node2vec_embd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5d0c3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9507255113526435, 0.9680239849015438, 0.8234308875642327, 0.8887482938002788]\n"
     ]
    }
   ],
   "source": [
    "### 5 DeepWalk方法\n",
    "from karateclub import DeepWalk\n",
    "model = DeepWalk(dimensions=64, walk_length=30, window_size=10)\n",
    "model.fit(G)\n",
    "deepwalk_embd = model.get_embedding()\n",
    "print(evaluate_cluster(intrinsic_list, intrinsic_clustering, deepwalk_embd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2df4d92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-24 14:32:18.439047: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-24 14:32:20.171904: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-06-24 14:32:24.032666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38223 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:02:00.0, compute capability: 8.0\n",
      "2023-06-24 14:32:24.034093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38223 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:41:00.0, compute capability: 8.0\n",
      "2023-06-24 14:32:24.326183: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.9771821781614743, 1.0, 0.9199535201640465]\n"
     ]
    }
   ],
   "source": [
    "### 6 LINE 方法\n",
    "from ge import LINE\n",
    "model = LINE(G,embedding_size=60,order='first');\n",
    "model.train(batch_size=1024,epochs=50,verbose=0);# train model\n",
    "LINE_embd = model.get_embeddings();# get embedding vectors\n",
    "\n",
    "LINE_embd = list(LINE_embd.values())\n",
    "print(evaluate_cluster(intrinsic_list, intrinsic_clustering, LINE_embd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "650e846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "### Correct Graph LLE\n",
    "###############################\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import normalize\n",
    "import scipy.linalg as lg\n",
    "\n",
    "def lle(graph, dim):\n",
    "    A = nx.to_numpy_array(graph, nodelist=sorted(graph.nodes()), weight='weight')\n",
    "    normalize(A, norm='l1', axis=1, copy=False)\n",
    "    I_n = np.eye(graph.number_of_nodes())\n",
    "    I_min_A = np.dot((I_n - A).T, (I_n - A))\n",
    "    w, v = lg.eig(I_min_A)\n",
    "    idx = np.argsort(w.real)\n",
    "    v = v[:, idx]\n",
    "    embedding = v[:, 1:(dim+1)]\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "494f3039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9685299604870004, 1.0, 0.8838846153846155, 1.0]\n"
     ]
    }
   ],
   "source": [
    "### 7 LLE 方法\n",
    "D = 15\n",
    "lle_embd = lle(G, D)\n",
    "print(evaluate_cluster(intrinsic_list, intrinsic_clustering, lle_embd))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
