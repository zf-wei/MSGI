{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97363fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 2 µs, total: 6 µs\n",
      "Wall time: 8.58 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### 生成输出目录的模块\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def generate_output(disturb: bool, filename):\n",
    "    # Generate the folder name with the current date\n",
    "    now = datetime.now()\n",
    "    if disturb:\n",
    "        folder_name = f\"Graph_Rmv_Stoch_{now.strftime('%Y-%m-%d-%H')}\"\n",
    "    else:\n",
    "        folder_name = f\"Graph_Rmv_Btwn_{now.strftime('%Y-%m-%d-%H')}\"\n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    output_dir = os.path.join(os.getcwd(), folder_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(output_dir, filename)\n",
    "\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3845633a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.28 s, sys: 14 s, total: 22.3 s\n",
      "Wall time: 9.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.generators.community import LFR_benchmark_graph\n",
    "\n",
    "n = 1000\n",
    "tau1 = 2  # Power-law exponent for the degree distribution\n",
    "tau2 = 1.1  # Power-law exponent for the community size distribution\n",
    "mu = 0.1  # Mixing parameter\n",
    "avg_deg = 25  # Average Degree\n",
    "max_deg = int(0.1 * n)  # Max Degree\n",
    "min_commu = 60  # Min Community Size\n",
    "max_commu = int(0.1 * n)  # Max Community Size\n",
    "\n",
    "G0 = LFR_benchmark_graph(\n",
    "    n, tau1, tau2, mu, average_degree=avg_deg, max_degree=max_deg, min_community=min_commu, max_community=max_commu,\n",
    "    seed=7\n",
    ")\n",
    "\n",
    "# Remove multi-edges and self-loops from G0\n",
    "G0 = nx.Graph(G0)\n",
    "selfloop_edges = list(nx.selfloop_edges(G0))\n",
    "G0.remove_edges_from(selfloop_edges)\n",
    "\n",
    "# Generate a timestamp for the output file names\n",
    "now = datetime.now()\n",
    "\n",
    "# Write the graph's edge list to a file\n",
    "edge_output_file = f\"edgelist_{now.strftime('%Y-%m-%d-%H')}.txt\"\n",
    "nx.write_edgelist(G0, edge_output_file, delimiter=' ', data=False)\n",
    "\n",
    "import numpy as np\n",
    "# Get intrinsic membership and save it to a file\n",
    "intrinsic_communities = {frozenset(G0.nodes[v][\"community\"]) for v in G0}\n",
    "intrinsic_membership = np.empty(G0.number_of_nodes(), dtype=int)\n",
    "for node in range(G0.number_of_nodes()):\n",
    "    for index, inner_set in enumerate(intrinsic_communities):\n",
    "        if node in inner_set:\n",
    "            intrinsic_membership[node] = index\n",
    "            break\n",
    "\n",
    "membership_output_file = f\"membership_{now.strftime('%Y-%m-%d-%H')}.txt\"\n",
    "np.savetxt(membership_output_file, intrinsic_membership, delimiter=' ', fmt='%d')\n",
    "\n",
    "# Get betweenness centrality and save it to a file\n",
    "betweenness = list(nx.betweenness_centrality(G0).values())\n",
    "betweenness_output_file = f\"betweenness_{now.strftime('%Y-%m-%d-%H')}.txt\"\n",
    "np.savetxt(betweenness_output_file, betweenness, delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "887950ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n### 读取存储的图的相关信息\\n### 从文件中读入内容并转化成 边列表\\nwith open(\\'edgelist_2023-07-11-17.txt\\', \\'r\\') as file:\\n    lines = file.readlines()\\n\\n### Process the lines and create a list of number pairs\\nedge_list = []\\nfor line in lines:\\n    pair = tuple(map(int, line.strip().split()))\\n    edge_list.append(pair)\\n\\n### Print the list of number pairs\\n#print(edge_list)\\n\\nimport networkx as nx\\n\\n### 新建一个图 \\nG0 = nx.Graph()\\n\\n### 向图添加边\\nG0.add_edges_from(edge_list)\\n\\n### 记录有几个结点\\nN = G0.number_of_nodes()\\n\\n### Load Community Info\\nimport numpy as np\\n\\nmembership_list = \"membership_2023-07-11-17.txt\"\\nintrinsic_membership = np.loadtxt(membership_list, dtype=int)\\n\\nbtwn_file = \"betweenness_2023-07-11-17.txt\"\\nbetweenness = np.loadtxt(btwn_file)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "### 读取存储的图的相关信息\n",
    "### 从文件中读入内容并转化成 边列表\n",
    "with open('edgelist_2023-07-11-17.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "### Process the lines and create a list of number pairs\n",
    "edge_list = []\n",
    "for line in lines:\n",
    "    pair = tuple(map(int, line.strip().split()))\n",
    "    edge_list.append(pair)\n",
    "\n",
    "### Print the list of number pairs\n",
    "#print(edge_list)\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "### 新建一个图 \n",
    "G0 = nx.Graph()\n",
    "\n",
    "### 向图添加边\n",
    "G0.add_edges_from(edge_list)\n",
    "\n",
    "### 记录有几个结点\n",
    "N = G0.number_of_nodes()\n",
    "\n",
    "### Load Community Info\n",
    "import numpy as np\n",
    "\n",
    "membership_list = \"membership_2023-07-11-17.txt\"\n",
    "intrinsic_membership = np.loadtxt(membership_list, dtype=int)\n",
    "\n",
    "btwn_file = \"betweenness_2023-07-11-17.txt\"\n",
    "betweenness = np.loadtxt(btwn_file)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "238ea626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 6 µs, total: 10 µs\n",
      "Wall time: 12.4 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### 生成删除顶点的顺序 模块\n",
    "import random\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "def nodes_sample(G, disturb: bool, number_of_nodes: int, percent, betweenness):\n",
    "    graph = G.copy()\n",
    "    sample_size = int(number_of_nodes*percent)\n",
    "    if disturb:\n",
    "        removed_nodes = random.sample(range(number_of_nodes), sample_size)\n",
    "        graph.remove_nodes_from(removed_nodes)\n",
    "        if nx.is_connected(graph):\n",
    "            return removed_nodes\n",
    "    else: \n",
    "        removed_nodes = random.choices(range(number_of_nodes), betweenness, k=sample_size)\n",
    "        graph.remove_nodes_from(removed_nodes)\n",
    "        if nx.is_connected(graph):\n",
    "            return removed_nodes\n",
    "        \n",
    "#nodes_sample(G0, N, 0.8)\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def generate_remove_list(G, disturb: bool, number_of_nodes, betweenness):\n",
    "    remove_procedure = []\n",
    "    for percent in np.arange(0.05, 0.86, 0.05):\n",
    "        ls = []\n",
    "        while len(ls)<50:\n",
    "            temp = nodes_sample(G = G, disturb = disturb, number_of_nodes = number_of_nodes, percent = percent, betweenness = betweenness)\n",
    "            if not temp is None:\n",
    "                ls.append(temp)\n",
    "        remove_procedure.append(ls)\n",
    "    filename = generate_output(disturb, \"0Remove_Procedure.txt\")\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(remove_procedure, file)\n",
    "    return remove_procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d37f517",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31 s, sys: 22.4 ms, total: 31 s\n",
      "Wall time: 31.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nwith open('Graph_Rmv_Stoch_2023-07-11-18/remove_procedure.txt', 'r') as file:\\n    loaded_data = json.load(file)\\nloaded_data == ls\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "remove_procedure = generate_remove_list(G0, True, G0.number_of_nodes(), betweenness)\n",
    "\n",
    "### 读取存储的删除顶点的顺序信息\n",
    "'''\n",
    "with open('Graph_Rmv_Stoch_2023-07-11-18/remove_procedure.txt', 'r') as file:\n",
    "    loaded_data = json.load(file)\n",
    "loaded_data == ls\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b3c250d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.6 ms, sys: 3.46 ms, total: 26 ms\n",
      "Wall time: 23.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "index = []\n",
    "for sublist_list in remove_procedure:\n",
    "    sublist_index = []\n",
    "    for sublist in sublist_list:\n",
    "        temp = np.ones(G0.number_of_nodes(), dtype=bool)\n",
    "        temp[sublist] = False\n",
    "        sublist_index.append(temp)\n",
    "    index.append(sublist_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6a7f10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.28 ms, sys: 460 µs, total: 1.74 ms\n",
      "Wall time: 3.91 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "import csv\n",
    "from datetime import date\n",
    "\n",
    "def save_SCORES_to_csv(scores, disturb: bool, filename):\n",
    "    \"\"\"\n",
    "    Saves a list of list of list to a CSV file with a double space separator.\n",
    "\n",
    "    Args:\n",
    "        scores (list): The list of list of list to be saved.\n",
    "        disturb (bool): A boolean indicating if disturbance is present.\n",
    "        filename (str): The name of the output CSV file.\n",
    "    \"\"\"\n",
    "    # Construct the full file path\n",
    "    file_path = generate_output(disturb, filename + \".csv\")\n",
    "\n",
    "    with open(file_path, 'w', newline='') as file:\n",
    "        writer = csv.writer(file, delimiter=' ')\n",
    "        for outer_list in scores:\n",
    "            for inner_list in outer_list:\n",
    "                writer.writerow(inner_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2d91f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 2 µs, total: 8 µs\n",
      "Wall time: 11.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "import csv\n",
    "from datetime import date\n",
    "\n",
    "def save_to_csv(content, disturb: bool, filename):\n",
    "    \"\"\"\n",
    "    Saves a list of 4-lists to a CSV file with a double space separator.\n",
    "    \n",
    "    Args:\n",
    "        scores (list): The list of 4-lists to be saved.\n",
    "        filename (str): The name of the output CSV file.\n",
    "    \"\"\"\n",
    "    # Construct the full file path\n",
    "    file_path = generate_output(disturb, filename+\".csv\")\n",
    "\n",
    "    with open(file_path, 'w', newline='') as file:\n",
    "        writer = csv.writer(file, delimiter=' ')\n",
    "        for content_list in content:\n",
    "            writer.writerow(content_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c5d7e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 419 ms, sys: 353 ms, total: 773 ms\n",
      "Wall time: 5.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from auxpack.eval_embd import eval_embd as EE\n",
    "from clusim.clustering import Clustering\n",
    "\n",
    "D=20\n",
    "K = len(np.unique(intrinsic_membership))\n",
    "wk=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315b520e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "### 1 Hope 方法\n",
    "from gem.embedding.hope import HOPE \n",
    "\n",
    "SCORES=[]\n",
    "\n",
    "MEAN = []\n",
    "STD = []\n",
    "\n",
    "for rp, idx in zip(remove_procedure,index):\n",
    "    scores = []\n",
    "    for realize, idxx in zip(rp, idx):\n",
    "        G=G0.copy()\n",
    "        G.remove_nodes_from(realize)\n",
    "        hope_model = HOPE(d=D, beta=0.01) \n",
    "        # A higher value of beta places more emphasis on capturing higher-order proximities\n",
    "        embd = hope_model.learn_embedding(graph=G, is_weighted=False, no_python=True)\n",
    "        intrin_list = intrinsic_membership[idxx]\n",
    "        intrin_Clus = Clustering({i: [intrin_list[i]] for i in range(len(intrin_list))})\n",
    "        K = len(np.unique(intrin_list))\n",
    "        score = EE(K,intrin_list,intrin_Clus, embd)\n",
    "        scores.append(score)\n",
    "    # Convert the list to a NumPy array for efficient computations\n",
    "    array = np.array(scores)\n",
    "    # Calculate the mean and standard deviation for each coordinate\n",
    "    mean = np.mean(array, axis=0)\n",
    "    std = np.std(array, axis=0)\n",
    "    print(mean,std)\n",
    "    MEAN.append(mean)\n",
    "    STD.append(std)\n",
    "    SCORES.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e7b2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "save_SCORES_to_csv(SCORES, True, \"1HOPE_SCORES\")\n",
    "save_to_csv(MEAN, True, \"1HOPE_MEAN\")\n",
    "save_to_csv(STD, True, \"1HOPE_STD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd07774",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate x-coordinates for the data points with a step size of 0.05\n",
    "x_values = np.arange(0.05, 0.86, 0.05)\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n",
    "\n",
    "# Plot the lines for columns 1 and 3 in the first subplot\n",
    "ax1.plot(x_values, [MEAN[i][0] for i in range(len(MEAN))], label='Column 1', color='tab:red')\n",
    "ax1.plot(x_values, [MEAN[i][2] for i in range(len(MEAN))], label='Column 3', color='tab:blue')\n",
    "ax1.fill_between(x_values, np.subtract([MEAN[i][0] for i in range(len(MEAN))], [STD[i][0] for i in range(len(STD))]),\n",
    "                 np.add([MEAN[i][0] for i in range(len(MEAN))], [STD[i][0] for i in range(len(STD))]), alpha=0.2, color='tab:red')\n",
    "ax1.fill_between(x_values, np.subtract([MEAN[i][2] for i in range(len(MEAN))], [STD[i][2] for i in range(len(STD))]),\n",
    "                 np.add([MEAN[i][2] for i in range(len(MEAN))], [STD[i][2] for i in range(len(STD))]), alpha=0.2, color='tab:blue')\n",
    "ax1.set_ylabel('Y-coordinate')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot the lines for columns 2 and 4 in the second subplot\n",
    "ax2.plot(x_values, [MEAN[i][1] for i in range(len(MEAN))], label='Column 2', color='tab:green')\n",
    "ax2.plot(x_values, [MEAN[i][3] for i in range(len(MEAN))], label='Column 4', color='tab:orange')\n",
    "ax2.fill_between(x_values, np.subtract([MEAN[i][1] for i in range(len(MEAN))], [STD[i][1] for i in range(len(STD))]),\n",
    "                 np.add([MEAN[i][1] for i in range(len(MEAN))], [STD[i][1] for i in range(len(STD))]), alpha=0.2, color='tab:green')\n",
    "ax2.fill_between(x_values, np.subtract([MEAN[i][3] for i in range(len(MEAN))], [STD[i][3] for i in range(len(STD))]),\n",
    "                 np.add([MEAN[i][3] for i in range(len(MEAN))], [STD[i][3] for i in range(len(STD))]), alpha=0.2, color='tab:orange')\n",
    "ax2.set_xlabel('X-coordinate')\n",
    "ax2.set_ylabel('Y-coordinate')\n",
    "ax2.legend()\n",
    "\n",
    "# Set the x-axis scale\n",
    "plt.xticks(np.arange(0.0, 0.9, 0.05))\n",
    "\n",
    "# Automatically determine the lower bound for the y-axis\n",
    "y_min = min([min(y) for y in MEAN])\n",
    "y_max = max([max(y) for y in MEAN])\n",
    "y_range = y_max - y_min\n",
    "y_offset = y_range * 0.1  # Adjust the offset as needed\n",
    "y_lower = y_min - y_offset - 0.06\n",
    "y_upper = 1.0\n",
    "ax1.set_ylim(y_lower, y_upper)\n",
    "ax2.set_ylim(y_lower, y_upper)\n",
    "\n",
    "# Set the y-axis tick marks\n",
    "y_tick_step = 0.02\n",
    "y_ticks = np.arange(y_lower, y_upper, y_tick_step)\n",
    "ax1.set_yticks(y_ticks)\n",
    "ax2.set_yticks(y_ticks)\n",
    "\n",
    "# Adjust the figure size\n",
    "fig.set_size_inches(10, 12)  # Increase the height of the figure\n",
    "\n",
    "##########################\n",
    "filename = \"1HOPE_SEPARATE\"\n",
    "##########################\n",
    "\n",
    "file_path = generate_output(True, filename+\".png\")\n",
    "plt.savefig(file_path)    \n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952bdba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate x-coordinates for the data points with a step size of 0.05\n",
    "x_values = np.arange(0.05, 0.86, 0.05)\n",
    "\n",
    "# Create a figure and axes\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the lines for columns 1 and 3 in the first subplot\n",
    "ax.plot(x_values, [MEAN[i][0] for i in range(len(MEAN))], label='Column 1', color='tab:red')\n",
    "ax.plot(x_values, [MEAN[i][2] for i in range(len(MEAN))], label='Column 3', color='tab:blue')\n",
    "ax.fill_between(x_values, np.subtract([MEAN[i][0] for i in range(len(MEAN))], [STD[i][0] for i in range(len(STD))]),\n",
    "                 np.add([MEAN[i][0] for i in range(len(MEAN))], [STD[i][0] for i in range(len(STD))]), alpha=0.2, color='tab:red')\n",
    "ax.fill_between(x_values, np.subtract([MEAN[i][2] for i in range(len(MEAN))], [STD[i][2] for i in range(len(STD))]),\n",
    "                 np.add([MEAN[i][2] for i in range(len(MEAN))], [STD[i][2] for i in range(len(STD))]), alpha=0.2, color='tab:blue')\n",
    "\n",
    "# Plot the lines for columns 2 and 4 in the second subplot\n",
    "ax.plot(x_values, [MEAN[i][1] for i in range(len(MEAN))], label='Column 2', color='tab:green')\n",
    "ax.plot(x_values, [MEAN[i][3] for i in range(len(MEAN))], label='Column 4', color='tab:orange')\n",
    "ax.fill_between(x_values, np.subtract([MEAN[i][1] for i in range(len(MEAN))], [STD[i][1] for i in range(len(STD))]),\n",
    "                 np.add([MEAN[i][1] for i in range(len(MEAN))], [STD[i][1] for i in range(len(STD))]), alpha=0.2, color='tab:green')\n",
    "ax.fill_between(x_values, np.subtract([MEAN[i][3] for i in range(len(MEAN))], [STD[i][3] for i in range(len(STD))]),\n",
    "                 np.add([MEAN[i][3] for i in range(len(MEAN))], [STD[i][3] for i in range(len(STD))]), alpha=0.2, color='tab:orange')\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('X-coordinate')\n",
    "ax.set_ylabel('Y-coordinate')\n",
    "ax.set_title('Merged Plot')\n",
    "\n",
    "# Set the x-axis scale\n",
    "plt.xticks(np.arange(0.0, 0.9, 0.05))\n",
    "\n",
    "# Automatically determine the lower bound for the y-axis\n",
    "y_min = min([min(y) for y in MEAN])\n",
    "y_max = max([max(y) for y in MEAN])\n",
    "y_range = y_max - y_min\n",
    "y_offset = y_range * 0.1  # Adjust the offset as needed\n",
    "y_lower = y_min - y_offset - 0.06\n",
    "y_upper = 1.0\n",
    "ax.set_ylim(y_lower, y_upper)\n",
    "\n",
    "# Set the y-axis tick marks\n",
    "y_tick_step = 0.02\n",
    "y_ticks = np.arange(y_lower, y_upper, y_tick_step)\n",
    "ax.set_yticks(y_ticks)\n",
    "\n",
    "# Add a legend\n",
    "ax.legend()\n",
    "\n",
    "# Adjust the figure size\n",
    "fig.set_size_inches(10, 6)\n",
    "##########################\n",
    "filename = \"1HOPE_TOTAL\"\n",
    "##########################\n",
    "\n",
    "file_path = generate_output(True, filename+\".png\")\n",
    "plt.savefig(file_path)    \n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
